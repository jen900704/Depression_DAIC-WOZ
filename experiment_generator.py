import pandas as pd
import os
from sklearn.model_selection import GroupShuffleSplit, train_test_split

# ================= è¨­å®šå€ =================
source_csv = "all_m5_clean_v_final.csv"  
output_base = "./experiment_sisman_scientific"
# =========================================

print("ğŸš€ [V5] é–‹å§‹å»ºæ§‹ã€Œç§‘å­¸éš¨æ©ŸæŠ½æ¨£ã€å°ç…§å¯¦é©—...")

# 1. è®€å–èˆ‡å‰ç½®è™•ç†
if not os.path.exists(source_csv):
    print(f"âŒ æ‰¾ä¸åˆ°ä¾†æºæª”æ¡ˆ: {source_csv}"); exit()

df = pd.read_csv(source_csv, sep=None, engine='python')

# ç¢ºä¿è·¯å¾‘èˆ‡ID
path_col = next((c for c in df.columns if c.lower() in ['path', 'file_path', 'filename']), None)
if not path_col: print("âŒ æ‰¾ä¸åˆ°è·¯å¾‘æ¬„ä½"); exit()
df['participant_id'] = df[path_col].apply(lambda x: os.path.basename(str(x)).split('_')[0])

# ç¢ºä¿ Label
label_col = next((c for c in df.columns if c.lower() in ['class_2', 'label', 'target']), None)
if not label_col: print("âŒ æ‰¾ä¸åˆ° Label"); exit()
df = df.dropna(subset=[label_col])

print(f"ğŸ‘¥ ç¸½äººæ•¸: {df['participant_id'].nunique()}")
print(f"ğŸ“Š ç¸½è³‡æ–™: {len(df)}")

# ==========================================
# ğŸ§  æ ¸å¿ƒé‚è¼¯ï¼šé›™ç›²éš¨æ©ŸæŠ½æ¨£
# ==========================================

# ç¬¬ä¸€æ­¥ï¼šé¸å‡º 20% çš„äººç•¶ä½œã€Œæ¸¬è©¦å°è±¡ã€(Test Subjects)
# é€™äº›äººæ˜¯æˆ‘å€‘é€™æ¬¡å¯¦é©—çš„ä¸»è§’ï¼Œæˆ‘å€‘è¦è§€å¯Ÿã€Œæœ‰æ²’æœ‰æ´©æ¼ã€å°é æ¸¬é€™ç¾¤äººæœ‰å¤šå¤§å½±éŸ¿
gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)
train_people_idx, test_people_idx = next(gss.split(df, groups=df['participant_id']))

df_background = df.iloc[train_people_idx].copy() # èƒŒæ™¯è·¯äºº (æ°¸é åœ¨è¨“ç·´é›†)
df_test_subjects = df.iloc[test_people_idx].copy() # æ¸¬è©¦å°è±¡ (æˆ‘å€‘è¦å°ä»–å€‘åšæ‰‹è…³)

print(f"\nğŸ”’ é–å®šæ¸¬è©¦å°è±¡: {df_test_subjects['participant_id'].nunique()} äºº")

# ç¬¬äºŒæ­¥ï¼šé‡å°æ¸¬è©¦å°è±¡ï¼Œé€²è¡Œã€Œéš¨æ©Ÿæ‰“æ•£åˆ‡åˆ†ã€ (Random Shuffle Split)
# é€™é¿å…äº†ã€Œå‰åŠæ®µ/å¾ŒåŠæ®µã€çš„æ™‚é–“åå·®ã€‚
# æˆ‘å€‘å°‡æ¯ä½æ¸¬è©¦å°è±¡çš„éŒ„éŸ³æª”éš¨æ©Ÿåˆ†æˆ 50% æ­·å²è³‡æ–™ (Leakage) å’Œ 50% ç•¶ä¸‹è³‡æ–™ (Test)
split_leak_history, split_exam_target = train_test_split(
    df_test_subjects, 
    test_size=0.5, 
    random_state=42, 
    stratify=df_test_subjects['participant_id'] # é—œéµï¼šç¢ºä¿æ¯å€‹äººéƒ½è¢«å‡å‹»åˆ‡åˆ†
)

print(f"   ğŸ“‚ æ­·å²è³‡æ–™ (Leak Source): {len(split_leak_history)} ç­† (éš¨æ©ŸæŠ½æ¨£)")
print(f"   ğŸ“‚ ç•¶ä¸‹è³‡æ–™ (Fixed Exam):  {len(split_exam_target)} ç­† (éš¨æ©ŸæŠ½æ¨£)")

# ==========================================
# ğŸ§ª å¯¦é©— A: åˆè¨ºç¯©æª¢ (Scenario: First Visit)
# ==========================================
print("\n[å¯¦é©— A] åˆè¨ºç¯©æª¢ (Strict No Leakage)...")
save_dir_A = os.path.join(output_base, "scenario_A_screening")
os.makedirs(save_dir_A, exist_ok=True)

# è¨“ç·´é›† = åªæœ‰èƒŒæ™¯è·¯äºº
train_A = df_background.copy()
# æ¸¬è©¦é›† = ç•¶ä¸‹è³‡æ–™
test_A = split_exam_target.copy()

# å­˜æª”
path_c, label_c = path_col, label_col
train_A.rename(columns={path_c: 'path', label_c: 'label'})[['path', 'label']].to_csv(os.path.join(save_dir_A, "train.csv"), index=False)
test_A.rename(columns={path_c: 'path', label_c: 'label'})[['path', 'label']].to_csv(os.path.join(save_dir_A, "test.csv"), index=False)

print(f"   ğŸ‘‰ Train: {len(train_A)} | Test: {len(test_A)}")
print(f"   ğŸ‘‰ é‚è¼¯: æ¨¡å‹å®Œå…¨æ²’è½éé€™ {df_test_subjects['participant_id'].nunique()} ä½ç—…äººçš„è²éŸ³ã€‚")


# ==========================================
# ğŸ§ª å¯¦é©— B: é•·æœŸç›£æ¸¬ (Scenario: Longitudinal Monitoring)
# ==========================================
print("\n[å¯¦é©— B] é•·æœŸç›£æ¸¬ (With Historical Leakage)...")
save_dir_B = os.path.join(output_base, "scenario_B_monitoring")
os.makedirs(save_dir_B, exist_ok=True)

# è¨“ç·´é›† = èƒŒæ™¯è·¯äºº + æ¸¬è©¦å°è±¡çš„æ­·å²è³‡æ–™ (Leakage)
train_B = pd.concat([df_background, split_leak_history])
# æ¸¬è©¦é›† = ç•¶ä¸‹è³‡æ–™ (çµ•å°è·Ÿ A ä¸€æ¨¡ä¸€æ¨£)
test_B = split_exam_target.copy()

# å­˜æª”
train_B.rename(columns={path_c: 'path', label_c: 'label'})[['path', 'label']].to_csv(os.path.join(save_dir_B, "train.csv"), index=False)
test_B.rename(columns={path_c: 'path', label_c: 'label'})[['path', 'label']].to_csv(os.path.join(save_dir_B, "test.csv"), index=False)

print(f"   ğŸ‘‰ Train: {len(train_B)} | Test: {len(test_B)}")
print(f"   ğŸ‘‰ é‚è¼¯: æ¨¡å‹åœ¨è¨“ç·´æ™‚è½éäº†é€™ {df_test_subjects['participant_id'].nunique()} ä½ç—…äººã€å…¶ä»–çš„ã€éŒ„éŸ³æª”ã€‚")
print(f"   âœ¨ ç§‘å­¸æ€§: Test Set å®Œå…¨å›ºå®šï¼Œå”¯ä¸€çš„è®Šå› æ˜¯ Training Set æ˜¯å¦åŒ…å«è©²äººçš„æ­·å²è³‡è¨Šã€‚")

print("\nâœ… ç§‘å­¸å°ç…§æ•¸æ“šç”Ÿæˆå®Œç•¢ï¼")
print(f"è³‡æ–™å¤¾: {output_base}")