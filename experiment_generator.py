import pandas as pd
import os
from sklearn.model_selection import GroupShuffleSplit, train_test_split

# ================= è¨­å®šå€ =================
source_csv = "train_m5_absolute.csv"  # æ›¿æ›æˆé€™å€‹æ“æœ‰ 6545 ç­†çš„å®Œæ•´æª”æ¡ˆ
output_base = "./experiment_sisman_scientific"
# =========================================

print("ğŸš€ [V6] é–‹å§‹å»ºæ§‹ã€Œç§‘å­¸éš¨æ©ŸæŠ½æ¨£ï¼šåš´æ ¼æ•¸é‡åŒ¹é…ç‰ˆ (Size-Matched)ã€å°ç…§å¯¦é©—...")

# 1. è®€å–èˆ‡å‰ç½®è™•ç†
if not os.path.exists(source_csv):
    print(f"âŒ æ‰¾ä¸åˆ°ä¾†æºæª”æ¡ˆ: {source_csv}"); exit()

df = pd.read_csv(source_csv, sep=None, engine='python')

# â­â­â­ 1ï¼šçœ‹åŸå§‹æª”æ¡ˆåˆ°åº•æœ‰å¤šå¤§ â­â­â­
print(f"ğŸ” [æŠ“æ¼] å‰›è®€å– CSV æ™‚çš„ç¸½ç­†æ•¸: {len(df)}") 

# ç¢ºä¿è·¯å¾‘èˆ‡ID
path_col = next((c for c in df.columns if c.lower() in ['path', 'file_path', 'filename']), None)
if not path_col: print("âŒ æ‰¾ä¸åˆ°è·¯å¾‘æ¬„ä½"); exit()
df['participant_id'] = df[path_col].apply(lambda x: os.path.basename(str(x)).split('_')[0])

# ç¢ºä¿ Label
label_col = next((c for c in df.columns if c.lower() in ['class_2', 'label', 'target']), None)
if not label_col: print("âŒ æ‰¾ä¸åˆ° Label"); exit()

# â­â­â­ 2ï¼šæª¢æŸ¥æœ‰å¤šå°‘ç­† Label æ˜¯ç©ºçš„ â­â­â­
print(f"ğŸ” [æŠ“æ¼] ç™¼ç¾æœ‰ {df[label_col].isna().sum()} ç­†è³‡æ–™æ²’æœ‰ Label (æº–å‚™è¢«åˆªé™¤)!")

df = df.dropna(subset=[label_col])

# â­â­â­ 3ï¼šåˆªé™¤å¾Œçš„æœ€çµ‚æ•¸é‡ â­â­â­
print(f"ğŸ” [æŠ“æ¼] åˆªé™¤æ²’æœ‰ Label çš„è³‡æ–™å¾Œï¼Œå‰©ä¸‹ç­†æ•¸: {len(df)}")

# ==========================================
# ğŸ§  æ ¸å¿ƒé‚è¼¯ï¼šé›™ç›²éš¨æ©ŸæŠ½æ¨£ + æ•¸é‡åŒ¹é…
# ==========================================

# ç¬¬ä¸€æ­¥ï¼šé¸å‡º 20% çš„äººç•¶ä½œã€Œæ¸¬è©¦å°è±¡ã€(Test Subjects)
gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)
train_people_idx, test_people_idx = next(gss.split(df, groups=df['participant_id']))

df_background = df.iloc[train_people_idx].copy() # èƒŒæ™¯è·¯äºº 
df_test_subjects = df.iloc[test_people_idx].copy() # æ¸¬è©¦å°è±¡ 

print(f"\nğŸ”’ é–å®šæ¸¬è©¦å°è±¡: {df_test_subjects['participant_id'].nunique()} äºº")

# ç¬¬äºŒæ­¥ï¼šé‡å°æ¸¬è©¦å°è±¡çš„åˆ‡ç‰‡ï¼Œé€²è¡Œã€Œéš¨æ©Ÿæ‰“æ•£åˆ‡åˆ†ã€ 
split_leak_history, split_exam_target = train_test_split(
    df_test_subjects, 
    test_size=0.5, 
    random_state=42, 
    stratify=df_test_subjects['participant_id'] 
)

print(f"   ğŸ“‚ æ­·å²è³‡æ–™ (Leak Source): {len(split_leak_history)} ç­†åˆ‡ç‰‡")
print(f"   ğŸ“‚ ç•¶ä¸‹è³‡æ–™ (Fixed Exam):  {len(split_exam_target)} ç­†åˆ‡ç‰‡")

# ç¬¬ä¸‰æ­¥ï¼šâ­ æ•¸é‡åŒ¹é… (Size-Matched Control) æ ¸å¿ƒæ©Ÿåˆ¶ â­
# è¨ˆç®—å¤–æ´©æ­·å²è³‡æ–™çš„åˆ‡ç‰‡æ•¸é‡
leak_size = len(split_leak_history)

# å¾èƒŒæ™¯è·¯äººä¸­ï¼Œéš¨æ©ŸæŠ½å‡ºå‰›å¥½ç­‰æ–¼ leak_size æ•¸é‡çš„åˆ‡ç‰‡ç•¶ä½œã€Œæ›¿èº«ã€
# å‰©ä¸‹çš„ç•¶ä½œã€Œæ‰“åº•åŸºç¤ã€
df_base_train, df_filler_train = train_test_split(
    df_background,
    test_size=leak_size,
    random_state=42
)

print(f"   âš–ï¸  ç‚ºäº†ç¶­æŒå…¬å¹³ï¼Œå¾è·¯äººä¸­æŠ½å‡º {len(df_filler_train)} ç­†åˆ‡ç‰‡ä½œç‚ºã€Œæ›¿èº«ã€")
print(f"   ğŸ§± å‰©ä¸‹çš„ {len(df_base_train)} ç­†åˆ‡ç‰‡ä½œç‚º A å’Œ B å…±åŒçš„ã€Œæ‰“åº•åŸºç¤ã€")

# ==========================================
# ğŸ§ª å¯¦é©— A: åˆè¨ºç¯©æª¢ (Scenario: First Visit)
# ==========================================
print("\n[å¯¦é©— A] åˆè¨ºç¯©æª¢ (Strict No Leakage, Size-Matched)...")
save_dir_A = os.path.join(output_base, "scenario_A_screening")
os.makedirs(save_dir_A, exist_ok=True)

# è¨“ç·´é›† = åŸºç¤è·¯äºº + è·¯äººæ›¿èº« (æ•¸é‡å®Œç¾è£œé½Š)
train_A = pd.concat([df_base_train, df_filler_train])
test_A = split_exam_target.copy()

# å­˜æª”
path_c, label_c = path_col, label_col
train_A.rename(columns={path_c: 'path', label_c: 'label'})[['path', 'label']].to_csv(os.path.join(save_dir_A, "train.csv"), index=False)
test_A.rename(columns={path_c: 'path', label_c: 'label'})[['path', 'label']].to_csv(os.path.join(save_dir_A, "test.csv"), index=False)

print(f"   ğŸ‘‰ Train: {len(train_A)} ç­† | Test: {len(test_A)} ç­†")
print(f"   ğŸ‘‰ é‚è¼¯: æ¨¡å‹å®Œå…¨æ²’è½éé€™ {df_test_subjects['participant_id'].nunique()} ä½ç—…äººçš„è²éŸ³ã€‚")


# ==========================================
# ğŸ§ª å¯¦é©— B: é•·æœŸç›£æ¸¬ (Scenario: Longitudinal Monitoring)
# ==========================================
print("\n[å¯¦é©— B] é•·æœŸç›£æ¸¬ (With Historical Leakage)...")
save_dir_B = os.path.join(output_base, "scenario_B_monitoring")
os.makedirs(save_dir_B, exist_ok=True)

# è¨“ç·´é›† = åŸºç¤è·¯äºº + æ¸¬è©¦å°è±¡çš„æ­·å²è³‡æ–™ (Leakage)
train_B = pd.concat([df_base_train, split_leak_history])
test_B = split_exam_target.copy()

# å­˜æª”
train_B.rename(columns={path_c: 'path', label_c: 'label'})[['path', 'label']].to_csv(os.path.join(save_dir_B, "train.csv"), index=False)
test_B.rename(columns={path_c: 'path', label_c: 'label'})[['path', 'label']].to_csv(os.path.join(save_dir_B, "test.csv"), index=False)

print(f"   ğŸ‘‰ Train: {len(train_B)} ç­† | Test: {len(test_B)} ç­†")
print(f"   ğŸ‘‰ é‚è¼¯: æ¨¡å‹åœ¨è¨“ç·´æ™‚è½éäº†é€™ {df_test_subjects['participant_id'].nunique()} ä½ç—…äººã€å…¶ä»–çš„ã€éŒ„éŸ³æª”ã€‚")
print(f"   âœ¨ ç§‘å­¸æ€§: A èˆ‡ B çš„ Train/Test æ•¸é‡ 100% å®Œå…¨ç›¸ç­‰ï¼Œå”¯ä¸€è®Šå› åªæœ‰æ­·å²è³‡è¨Šï¼")

print("\nâœ… å°ç…§æ•¸æ“šç”Ÿæˆå®Œç•¢ï¼")
print(f"è³‡æ–™å¤¾: {output_base}")
